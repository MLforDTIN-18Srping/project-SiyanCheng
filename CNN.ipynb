{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Analysis with CNN & LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPU and 4 cores of CPU\n",
      "loading data...\n",
      "loading complete!\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FP = 'train.csv'\n",
    "TEST_FP = 'test.csv'\n",
    "MAX_NUM_WORDS = 10000\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "\n",
    "#set gpu config\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)\n",
    "print 'Using 1 GPU and 4 cores of CPU'\n",
    "\n",
    "#read data\n",
    "print 'loading data...'\n",
    "train_data, test_data = pd.read_csv('train.csv'), pd.read_csv('test.csv')\n",
    "texts = train_data.values[:,1]\n",
    "labels = train_data.values[:,2:]\n",
    "print 'loading complete!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing text and turing them into sequences...\n",
      "process complete!\n",
      "pading sequences...\n",
      "padding complete!\n"
     ]
    }
   ],
   "source": [
    "print 'Tokenizing text and turing them into sequences...'\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "#sequences is a array of number[123, 456, 12 ...]\n",
    "print 'process complete!'\n",
    "\n",
    "#word index is the dictionary of sequences\n",
    "word_index = tokenizer.word_index\n",
    "print 'pading sequences...'\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print 'padding complete!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. shuffling data and split for Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "#turn the labels into categotical\n",
    "label = dict()\n",
    "for i in range(labels.shape[1]):  \n",
    "    label[str(i)] = to_categorical(np.asarray(labels[:,i]))\n",
    "    \n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "for i in range(labels.shape[1]): \n",
    "    label[str(i)] = label[str(i)][indices]\n",
    "#shuffle the data\n",
    "VALIDATION_SPLIT = 0.2\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Read GloVe pre-trained embedding and implement embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading pre-trained word embedding...\n",
      "reading complete!\n",
      "making embedding matrix..\n",
      "process complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "BASE_DIR = ''\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove')\n",
    "#read pre-trained word embedding and turn them into a dictionary call embedding_index\n",
    "print 'reading pre-trained word embedding...'\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "print 'reading complete!' \n",
    "#\n",
    "print 'making embedding matrix..'\n",
    "EMBEDDING_DIM = 300\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print 'process complete!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'global_max_pooling1d_3_10/Max:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model_label1.h5')\n",
    "model.layers[7].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using CNN to train for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "#y_train = label['0'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "#y_val = label['0'][-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. First Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/10\n",
      "127657/127657 [==============================] - 15s - loss: 0.2000 - acc: 0.9294 - val_loss: 0.1539 - val_acc: 0.9471\n",
      "Epoch 2/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1423 - acc: 0.9503 - val_loss: 0.1492 - val_acc: 0.9497\n",
      "Epoch 3/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1251 - acc: 0.9560 - val_loss: 0.1577 - val_acc: 0.9515\n",
      "Epoch 4/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1137 - acc: 0.9606 - val_loss: 0.1674 - val_acc: 0.9524\n",
      "Epoch 5/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0979 - acc: 0.9663 - val_loss: 0.2205 - val_acc: 0.9470\n",
      "Epoch 6/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0858 - acc: 0.9707 - val_loss: 0.1843 - val_acc: 0.9421\n",
      "Epoch 7/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0755 - acc: 0.9751 - val_loss: 0.2659 - val_acc: 0.9403\n",
      "Epoch 8/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0661 - acc: 0.9785 - val_loss: 0.2468 - val_acc: 0.9511\n",
      "Epoch 9/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0589 - acc: 0.9813 - val_loss: 0.2793 - val_acc: 0.9495\n",
      "Epoch 10/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0543 - acc: 0.9830 - val_loss: 0.3165 - val_acc: 0.9491\n"
     ]
    }
   ],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['0'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['0'][-num_validation_samples:]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "model.save('model_label1.h5')\n",
    "del model  \n",
    "#model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Second Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0427 - acc: 0.9902 - val_loss: 0.0527 - val_acc: 0.9891\n",
      "Epoch 2/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0356 - acc: 0.9907 - val_loss: 0.0705 - val_acc: 0.9896\n",
      "Epoch 3/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0336 - acc: 0.9912 - val_loss: 0.0580 - val_acc: 0.9895\n",
      "Epoch 4/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0335 - acc: 0.9919 - val_loss: 0.0646 - val_acc: 0.9893\n",
      "Epoch 5/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0310 - acc: 0.9924 - val_loss: 0.0815 - val_acc: 0.9893\n",
      "Epoch 6/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0325 - acc: 0.9932 - val_loss: 0.0766 - val_acc: 0.9890\n",
      "Epoch 7/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0323 - acc: 0.9940 - val_loss: 0.0971 - val_acc: 0.9877\n",
      "Epoch 8/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0342 - acc: 0.9943 - val_loss: 0.1204 - val_acc: 0.9882\n",
      "Epoch 9/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0397 - acc: 0.9945 - val_loss: 0.1279 - val_acc: 0.9876\n",
      "Epoch 10/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0423 - acc: 0.9943 - val_loss: 0.1346 - val_acc: 0.9878\n"
     ]
    }
   ],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['1'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['1'][-num_validation_samples:]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "model.save('model_label2.h5')\n",
    "del model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Third Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.2004 - acc: 0.9668 - val_loss: 0.1186 - val_acc: 0.9711\n",
      "Epoch 2/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.1065 - acc: 0.9729 - val_loss: 0.1776 - val_acc: 0.9686\n",
      "Epoch 3/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0963 - acc: 0.9757 - val_loss: 0.1302 - val_acc: 0.9720\n",
      "Epoch 4/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0897 - acc: 0.9776 - val_loss: 0.1693 - val_acc: 0.9498\n",
      "Epoch 5/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0828 - acc: 0.9803 - val_loss: 0.1738 - val_acc: 0.9718\n",
      "Epoch 6/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0764 - acc: 0.9822 - val_loss: 0.1905 - val_acc: 0.9619\n",
      "Epoch 7/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0704 - acc: 0.9846 - val_loss: 0.1801 - val_acc: 0.9610\n",
      "Epoch 8/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0683 - acc: 0.9863 - val_loss: 0.3060 - val_acc: 0.9669\n",
      "Epoch 9/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0713 - acc: 0.9869 - val_loss: 0.2352 - val_acc: 0.9665\n",
      "Epoch 10/10\n",
      "127657/127657 [==============================] - 13s - loss: 0.0669 - acc: 0.9889 - val_loss: 0.2692 - val_acc: 0.9601\n"
     ]
    }
   ],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['2'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['2'][-num_validation_samples:]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "model.save('model_label3.h5')\n",
    "del model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Fourth Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/10\n",
      "127657/127657 [==============================] - 15s - loss: 0.0501 - acc: 0.9967 - val_loss: 0.0417 - val_acc: 0.9974\n",
      "Epoch 2/10\n",
      "127657/127657 [==============================] - 15s - loss: 0.0496 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9974\n",
      "Epoch 3/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0496 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9974\n",
      "Epoch 4/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0496 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9974\n",
      "Epoch 5/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0496 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9974\n",
      "Epoch 6/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0496 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9974\n",
      "Epoch 7/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0496 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9974\n",
      "Epoch 8/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0496 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9974\n",
      "Epoch 9/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0496 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9974\n",
      "Epoch 10/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.0496 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9974\n"
     ]
    }
   ],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['3'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['3'][-num_validation_samples:]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "model.save('model_label4.h5')\n",
    "del model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Fifth Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.7887 - acc: 0.9508 - val_loss: 0.8017 - val_acc: 0.9500\n",
      "Epoch 2/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.7887 - acc: 0.9508 - val_loss: 0.8017 - val_acc: 0.9500\n",
      "Epoch 3/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.7887 - acc: 0.9508 - val_loss: 0.8017 - val_acc: 0.9500\n",
      "Epoch 4/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.7887 - acc: 0.9508 - val_loss: 0.8017 - val_acc: 0.9500\n",
      "Epoch 5/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.7887 - acc: 0.9508 - val_loss: 0.8017 - val_acc: 0.9500\n",
      "Epoch 6/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.7887 - acc: 0.9508 - val_loss: 0.8017 - val_acc: 0.9500\n",
      "Epoch 7/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.7887 - acc: 0.9508 - val_loss: 0.8017 - val_acc: 0.9500\n",
      "Epoch 8/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.7887 - acc: 0.9508 - val_loss: 0.8017 - val_acc: 0.9500\n",
      "Epoch 9/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.7887 - acc: 0.9508 - val_loss: 0.8017 - val_acc: 0.9500\n",
      "Epoch 10/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.7887 - acc: 0.9508 - val_loss: 0.8017 - val_acc: 0.9500\n"
     ]
    }
   ],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['4'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['4'][-num_validation_samples:]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "\n",
    "model.save('model_label5.h5')\n",
    "del model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI. Sixth Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1432 - acc: 0.9911 - val_loss: 0.1331 - val_acc: 0.9917\n",
      "Epoch 2/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1432 - acc: 0.9911 - val_loss: 0.1331 - val_acc: 0.9917\n",
      "Epoch 3/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1432 - acc: 0.9911 - val_loss: 0.1331 - val_acc: 0.9917\n",
      "Epoch 4/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1432 - acc: 0.9911 - val_loss: 0.1331 - val_acc: 0.9917\n",
      "Epoch 5/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1432 - acc: 0.9911 - val_loss: 0.1331 - val_acc: 0.9917\n",
      "Epoch 6/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1432 - acc: 0.9911 - val_loss: 0.1331 - val_acc: 0.9917\n",
      "Epoch 7/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1432 - acc: 0.9911 - val_loss: 0.1331 - val_acc: 0.9917\n",
      "Epoch 8/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1432 - acc: 0.9911 - val_loss: 0.1331 - val_acc: 0.9917\n",
      "Epoch 9/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1432 - acc: 0.9911 - val_loss: 0.1331 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      "127657/127657 [==============================] - 14s - loss: 0.1432 - acc: 0.9911 - val_loss: 0.1331 - val_acc: 0.9917\n"
     ]
    }
   ],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['5'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['5'][-num_validation_samples:]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "model.save('model_label6.h5')\n",
    "del model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Caculating overall accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31744/31914 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "y_pred = dict()\n",
    "for i in range(labels.shape[1]):\n",
    "    model = load_model('model_label'+str(i+1)+'.h5')\n",
    "    y_pred[str(i)] = model.predict(x_val, batch_size = 128, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc score for CNN is: 0.502107517048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_pred = np.vstack((y_pred['0'][:,1], y_pred['1'][:,1], y_pred['2'][:,1], y_pred['3'][:,1], y_pred['4'][:,1], \\\n",
    "                     y_pred['5'][:,1])).reshape(-1,6)\n",
    "\n",
    "yt = labels[indices][:-num_validation_samples]\n",
    "yv = np.array(labels[indices][-num_validation_samples:], dtype = float)\n",
    "\n",
    "print 'roc score for CNN is:',roc_auc_score(yv, roc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.819326941154\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(y_pred['0'].shape[0]):\n",
    "        if y_pred[str(i)][j,0] > y_pred[str(i)][j,1]:\n",
    "            y_pred[str(i)][j,:] = np.array([1,0]).reshape((1,2))\n",
    "        else:\n",
    "            y_pred[str(i)][j,:] = np.array([0,1]).reshape((1,2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_acc(y_pred, y_val):\n",
    "    num_samples = y_pred['0'].shape[0]\n",
    "    num_correct = 0\n",
    "    for i in range(num_samples):\n",
    "        if np.array_equal(y_pred['0'][i,:], label['0'][i,:]) and np.array_equal(y_pred['1'][i,:], label['1'][i,:]) and \\\n",
    "        np.array_equal(y_pred['2'][i,:], label['2'][i,:]) and np.array_equal(y_pred['3'][i,:], label['3'][i,:]) and \\\n",
    "        np.array_equal(y_pred['4'][i,:], label['4'][i,:]) and np.array_equal(y_pred['5'][i,:], label['5'][i,:]):\n",
    "            num_correct = num_correct + 1\n",
    "    return float(num_correct)/float(num_samples)\n",
    "print 'accuracy:',compute_acc(y_pred, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Vanila CNN for all label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9672\n",
      " ROC-AUC - epoch: 1 - score: 0.932962\n",
      "127657/127657 [==============================] - 17s - loss: 0.1014 - acc: 0.9672 - val_loss: 0.0834 - val_acc: 0.9722\n",
      "Epoch 2/10\n",
      "127360/127657 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9727\n",
      " ROC-AUC - epoch: 2 - score: 0.942005\n",
      "127657/127657 [==============================] - 17s - loss: 0.0791 - acc: 0.9727 - val_loss: 0.0788 - val_acc: 0.9727\n",
      "Epoch 3/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9756\n",
      " ROC-AUC - epoch: 3 - score: 0.956951\n",
      "127657/127657 [==============================] - 17s - loss: 0.0694 - acc: 0.9756 - val_loss: 0.0653 - val_acc: 0.9775\n",
      "Epoch 4/10\n",
      "127360/127657 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9800\n",
      " ROC-AUC - epoch: 4 - score: 0.960213\n",
      "127657/127657 [==============================] - 17s - loss: 0.0560 - acc: 0.9800 - val_loss: 0.0672 - val_acc: 0.9765\n",
      "Epoch 5/10\n",
      "127488/127657 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9817\n",
      " ROC-AUC - epoch: 5 - score: 0.961240\n",
      "127657/127657 [==============================] - 17s - loss: 0.0500 - acc: 0.9817 - val_loss: 0.0651 - val_acc: 0.9789\n",
      "Epoch 6/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9831\n",
      " ROC-AUC - epoch: 6 - score: 0.958332\n",
      "127657/127657 [==============================] - 17s - loss: 0.0449 - acc: 0.9831 - val_loss: 0.0675 - val_acc: 0.9781\n",
      "Epoch 7/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9846\n",
      " ROC-AUC - epoch: 7 - score: 0.958380\n",
      "127657/127657 [==============================] - 17s - loss: 0.0402 - acc: 0.9846 - val_loss: 0.0693 - val_acc: 0.9772\n",
      "Epoch 8/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9858\n",
      " ROC-AUC - epoch: 8 - score: 0.956784\n",
      "127657/127657 [==============================] - 17s - loss: 0.0362 - acc: 0.9858 - val_loss: 0.0752 - val_acc: 0.9772\n",
      "Epoch 9/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9870\n",
      " ROC-AUC - epoch: 9 - score: 0.956110\n",
      "127657/127657 [==============================] - 17s - loss: 0.0331 - acc: 0.9870 - val_loss: 0.0792 - val_acc: 0.9781\n",
      "Epoch 10/10\n",
      "127360/127657 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9880\n",
      " ROC-AUC - epoch: 10 - score: 0.954629\n",
      "127657/127657 [==============================] - 17s - loss: 0.0304 - acc: 0.9880 - val_loss: 0.0786 - val_acc: 0.9766\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dropout\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "#x = Dropout(0.2)(embedded_sequences)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(6, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['5'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['5'][-num_validation_samples:]\n",
    "\n",
    "\n",
    "yt = labels[indices][:-num_validation_samples]\n",
    "yv = np.array(labels[indices][-num_validation_samples:], dtype = float)\n",
    "\n",
    "ra = RocAucEvaluation(validation_data=(x_val, yv), interval = 1)\n",
    "\n",
    "#for i in range(1,10):\n",
    "model.fit(x_train, yt,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          callbacks = [ra],\n",
    "          validation_data=(x_val, yv))\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('model_alllabel.h5')\n",
    "#del model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with 0.2 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/10\n",
      "127232/127657 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9687\n",
      " ROC-AUC - epoch: 1 - score: 0.952840\n",
      "127657/127657 [==============================] - 18s - loss: 0.0973 - acc: 0.9688 - val_loss: 0.0649 - val_acc: 0.9773\n",
      "Epoch 2/10\n",
      "127360/127657 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9781\n",
      " ROC-AUC - epoch: 2 - score: 0.961677\n",
      "127657/127657 [==============================] - 17s - loss: 0.0637 - acc: 0.9781 - val_loss: 0.0602 - val_acc: 0.9789\n",
      "Epoch 3/10\n",
      "127488/127657 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9796\n",
      " ROC-AUC - epoch: 3 - score: 0.962536\n",
      "127657/127657 [==============================] - 17s - loss: 0.0581 - acc: 0.9796 - val_loss: 0.0605 - val_acc: 0.9790\n",
      "Epoch 4/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9807\n",
      " ROC-AUC - epoch: 4 - score: 0.961976\n",
      "127657/127657 [==============================] - 17s - loss: 0.0535 - acc: 0.9807 - val_loss: 0.0605 - val_acc: 0.9791\n",
      "Epoch 5/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9818\n",
      " ROC-AUC - epoch: 5 - score: 0.960572\n",
      "127657/127657 [==============================] - 17s - loss: 0.0492 - acc: 0.9818 - val_loss: 0.0648 - val_acc: 0.9791\n",
      "Epoch 6/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9830\n",
      " ROC-AUC - epoch: 6 - score: 0.956633\n",
      "127657/127657 [==============================] - 17s - loss: 0.0451 - acc: 0.9830 - val_loss: 0.0643 - val_acc: 0.9787\n",
      "Epoch 7/10\n",
      "127488/127657 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9839\n",
      " ROC-AUC - epoch: 7 - score: 0.956213\n",
      "127657/127657 [==============================] - 17s - loss: 0.0415 - acc: 0.9839 - val_loss: 0.0692 - val_acc: 0.9787\n",
      "Epoch 8/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9849\n",
      " ROC-AUC - epoch: 8 - score: 0.958377\n",
      "127657/127657 [==============================] - 17s - loss: 0.0384 - acc: 0.9849 - val_loss: 0.0730 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9857\n",
      " ROC-AUC - epoch: 9 - score: 0.956086\n",
      "127657/127657 [==============================] - 17s - loss: 0.0359 - acc: 0.9857 - val_loss: 0.0763 - val_acc: 0.9778\n",
      "Epoch 10/10\n",
      "127488/127657 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9866\n",
      " ROC-AUC - epoch: 10 - score: 0.955552\n",
      "127657/127657 [==============================] - 17s - loss: 0.0339 - acc: 0.9866 - val_loss: 0.0810 - val_acc: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa138c01e50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dropout\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "#x = Dropout(0.2)(embedded_sequences)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(6, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['5'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['5'][-num_validation_samples:]\n",
    "\n",
    "\n",
    "yt = labels[indices][:-num_validation_samples]\n",
    "yv = np.array(labels[indices][-num_validation_samples:], dtype = float)\n",
    "\n",
    "ra = RocAucEvaluation(validation_data=(x_val, yv), interval = 1)\n",
    "\n",
    "#for i in range(1,10):\n",
    "model.fit(x_train, yt,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          callbacks = [ra],\n",
    "          validation_data=(x_val, yv))\n",
    "\n",
    "#model.save('model_alllabel.h5')\n",
    "#del model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with 0.5 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/10\n",
      "127232/127657 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9645\n",
      " ROC-AUC - epoch: 1 - score: 0.922515\n",
      "127657/127657 [==============================] - 18s - loss: 0.1069 - acc: 0.9645 - val_loss: 0.1096 - val_acc: 0.9704\n",
      "Epoch 2/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9768\n",
      " ROC-AUC - epoch: 2 - score: 0.957949\n",
      "127657/127657 [==============================] - 17s - loss: 0.0690 - acc: 0.9768 - val_loss: 0.0660 - val_acc: 0.9784\n",
      "Epoch 3/10\n",
      "127488/127657 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9790\n",
      " ROC-AUC - epoch: 3 - score: 0.961654\n",
      "127657/127657 [==============================] - 17s - loss: 0.0605 - acc: 0.9790 - val_loss: 0.0637 - val_acc: 0.9788\n",
      "Epoch 4/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9801\n",
      " ROC-AUC - epoch: 4 - score: 0.961788\n",
      "127657/127657 [==============================] - 17s - loss: 0.0559 - acc: 0.9801 - val_loss: 0.0621 - val_acc: 0.9786\n",
      "Epoch 5/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9811\n",
      " ROC-AUC - epoch: 5 - score: 0.959933\n",
      "127657/127657 [==============================] - 17s - loss: 0.0517 - acc: 0.9811 - val_loss: 0.0631 - val_acc: 0.9784\n",
      "Epoch 6/10\n",
      "127360/127657 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9822\n",
      " ROC-AUC - epoch: 6 - score: 0.959776\n",
      "127657/127657 [==============================] - 17s - loss: 0.0478 - acc: 0.9822 - val_loss: 0.0666 - val_acc: 0.9763\n",
      "Epoch 7/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9832\n",
      " ROC-AUC - epoch: 7 - score: 0.957969\n",
      "127657/127657 [==============================] - 17s - loss: 0.0444 - acc: 0.9832 - val_loss: 0.0672 - val_acc: 0.9773\n",
      "Epoch 8/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9839\n",
      " ROC-AUC - epoch: 8 - score: 0.955834\n",
      "127657/127657 [==============================] - 17s - loss: 0.0421 - acc: 0.9839 - val_loss: 0.0661 - val_acc: 0.9775\n",
      "Epoch 9/10\n",
      "127360/127657 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9846\n",
      " ROC-AUC - epoch: 9 - score: 0.955207\n",
      "127657/127657 [==============================] - 17s - loss: 0.0400 - acc: 0.9845 - val_loss: 0.0757 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9852\n",
      " ROC-AUC - epoch: 10 - score: 0.950248\n",
      "127657/127657 [==============================] - 17s - loss: 0.0380 - acc: 0.9852 - val_loss: 0.0773 - val_acc: 0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1381e4c90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dropout\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "#x = Dropout(0.2)(embedded_sequences)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(6, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['5'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['5'][-num_validation_samples:]\n",
    "\n",
    "\n",
    "yt = labels[indices][:-num_validation_samples]\n",
    "yv = np.array(labels[indices][-num_validation_samples:], dtype = float)\n",
    "\n",
    "ra = RocAucEvaluation(validation_data=(x_val, yv), interval = 1)\n",
    "\n",
    "#for i in range(1,10):\n",
    "model.fit(x_train, yt,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          callbacks = [ra],\n",
    "          validation_data=(x_val, yv))\n",
    "\n",
    "#model.save('model_alllabel.h5')\n",
    "#del model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with weight decay & EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/10\n",
      "127232/127657 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9713\n",
      " ROC-AUC - epoch: 1 - score: 0.955589\n",
      "127657/127657 [==============================] - 17s - loss: 0.0936 - acc: 0.9713 - val_loss: 0.0659 - val_acc: 0.9779\n",
      "Epoch 2/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9786\n",
      " ROC-AUC - epoch: 2 - score: 0.960413\n",
      "127657/127657 [==============================] - 16s - loss: 0.0637 - acc: 0.9786 - val_loss: 0.0631 - val_acc: 0.9789\n",
      "Epoch 3/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9798\n",
      " ROC-AUC - epoch: 3 - score: 0.961881\n",
      "127657/127657 [==============================] - 16s - loss: 0.0585 - acc: 0.9798 - val_loss: 0.0607 - val_acc: 0.9793\n",
      "Epoch 4/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9809\n",
      " ROC-AUC - epoch: 4 - score: 0.961395\n",
      "127657/127657 [==============================] - 16s - loss: 0.0536 - acc: 0.9809 - val_loss: 0.0607 - val_acc: 0.9791\n",
      "Epoch 5/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9820\n",
      " ROC-AUC - epoch: 5 - score: 0.958117\n",
      "127657/127657 [==============================] - 16s - loss: 0.0492 - acc: 0.9820 - val_loss: 0.0677 - val_acc: 0.9791\n",
      "Epoch 6/10\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9830\n",
      " ROC-AUC - epoch: 6 - score: 0.958610\n",
      "127657/127657 [==============================] - 16s - loss: 0.0450 - acc: 0.9830 - val_loss: 0.0656 - val_acc: 0.9785\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1372cbcd0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "#x = Dropout(0.2)(embedded_sequences)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "preds = Dense(6, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['5'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['5'][-num_validation_samples:]\n",
    "\n",
    "\n",
    "yt = labels[indices][:-num_validation_samples]\n",
    "yv = np.array(labels[indices][-num_validation_samples:], dtype = float)\n",
    "\n",
    "ra = RocAucEvaluation(validation_data=(x_val, yv), interval = 1)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0.001, patience=2, verbose=1)\n",
    "\n",
    "#for i in range(1,10):\n",
    "model.fit(x_train, yt,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          callbacks = [ra, early_stopping],\n",
    "          validation_data=(x_val, yv))\n",
    "\n",
    "#model.save('model_alllabel.h5')\n",
    "#del model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. CNN trained by 1000 samples, 2000 samples... (Samples are chose randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############1000\n",
      "epoch0\n",
      "epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "epoch5\n",
      "epoch6\n",
      "epoch7\n",
      "epoch8\n",
      "epoch9\n",
      "#############2000\n",
      "epoch0\n",
      "epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "epoch5\n",
      "epoch6\n",
      "epoch7\n",
      "epoch8\n",
      "epoch9\n",
      "#############3000\n",
      "epoch0\n",
      "epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "epoch5\n",
      "epoch6\n",
      "epoch7\n",
      "epoch8\n",
      "epoch9\n",
      "#############4000\n",
      "epoch0\n",
      "epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "epoch5\n",
      "epoch6\n",
      "epoch7\n",
      "epoch8\n",
      "epoch9\n",
      "#############5000\n",
      "epoch0\n",
      "epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "epoch5\n",
      "epoch6\n",
      "epoch7\n",
      "epoch8\n",
      "epoch9\n",
      "#############6000\n",
      "epoch0\n",
      "epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "epoch5\n",
      "epoch6\n",
      "epoch7\n",
      "epoch8\n",
      "epoch9\n",
      "#############7000\n",
      "epoch0\n",
      "epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "epoch5\n",
      "epoch6\n",
      "epoch7\n",
      "epoch8\n",
      "epoch9\n",
      "#############8000\n",
      "epoch0\n",
      "epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "epoch5\n",
      "epoch6\n",
      "epoch7\n",
      "epoch8\n",
      "epoch9\n",
      "#############9000\n",
      "epoch0\n",
      "epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "epoch5\n",
      "epoch6\n",
      "epoch7\n",
      "epoch8\n",
      "epoch9\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dropout\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['5'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['5'][-num_validation_samples:]\n",
    "\n",
    "\n",
    "yt = np.array(labels[indices][:-num_validation_samples], dtype = float)\n",
    "yv = np.array(labels[indices][-num_validation_samples:], dtype = float)\n",
    "\n",
    "#ra = RocAucEvaluation(validation_data=(x_val, yv), interval = 1)\n",
    "\n",
    "final_result = []\n",
    "\n",
    "for j in range(1000,10000,1000):\n",
    "    print '#############'+str(j)\n",
    "    \n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=False)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    #x = Dropout(0.2)(embedded_sequences)\n",
    "    x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv1D(128, 5, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv1D(128, 5, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    preds = Dense(6, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "    #ra = RocAucEvaluation(validation_data=(x_val, yv), interval = 1)\n",
    "    \n",
    "    result_list = []\n",
    "    for i in range(10):\n",
    "        print 'epoch'+str(i)\n",
    "        model.fit(x_train[0:j], yt[0:j],\n",
    "                  batch_size=128,\n",
    "                  #epochs=1,\n",
    "                  verbose = 0,\n",
    "                  #callbacks = [ra],\n",
    "                  validation_data=(x_val, yv))\n",
    "        \n",
    "        y_pred = model.predict(x_val, verbose=0)\n",
    "        validation_score = roc_auc_score(yv, y_pred)\n",
    "        y_pred = model.predict(x_train[0:j], verbose=0)\n",
    "        train_score = roc_auc_score(yt[0:j], y_pred)\n",
    "        \n",
    "        #print train_score\n",
    "        #print validation_score\n",
    "        result = [train_score, validation_score]\n",
    "        \n",
    "        result_list.append(result)\n",
    "    final_result.append(result_list)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('data_without_modelpool.npy',np.array(final_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8*. Semi-supervised CNN using QBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############0\n",
      "epoch0\n",
      "0.588079372656\n",
      "0.618648627958\n",
      "0.636106957702\n",
      "0.646597974553\n",
      "0.649607063427\n",
      "0.656887912779\n",
      "0.652243212736\n",
      "0.649529165931\n",
      "epoch1\n",
      "0.625724678322\n",
      "0.656110114116\n",
      "0.661268089363\n",
      "0.67091391962\n",
      "0.668335661009\n",
      "0.681400796209\n",
      "0.675588335344\n",
      "0.654139818341\n",
      "epoch2\n",
      "0.673124302979\n",
      "0.702140367152\n",
      "0.695841705551\n",
      "0.70286768254\n",
      "0.690066695845\n",
      "0.716421916486\n",
      "0.705391642738\n",
      "0.689137924385\n",
      "epoch3\n",
      "0.715213460075\n",
      "0.745425478907\n",
      "0.724746229252\n",
      "0.732906536503\n",
      "0.712267132285\n",
      "0.746212483621\n",
      "0.742946320206\n",
      "0.728345759917\n",
      "epoch4\n",
      "0.75375935421\n",
      "0.773012719144\n",
      "0.749429059065\n",
      "0.76500305183\n",
      "0.739936033424\n",
      "0.781538859238\n",
      "0.77152895579\n",
      "0.759964072696\n",
      "complete prediction\n",
      "complete computing norm\n",
      "#############1\n",
      "epoch0\n",
      "0.816442462231\n",
      "0.842507677161\n",
      "0.823214662827\n",
      "0.831710678784\n",
      "0.787834614203\n",
      "0.780899597389\n",
      "0.804662390104\n",
      "0.82288552344\n",
      "epoch1\n",
      "0.929218660873\n",
      "0.924755940918\n",
      "0.92613539401\n",
      "0.901496639005\n",
      "0.874022351853\n",
      "0.922334712706\n",
      "0.895579394667\n",
      "0.900359128993\n",
      "epoch2\n",
      "0.945855606777\n",
      "0.933881947873\n",
      "0.929303442641\n",
      "0.922958484679\n",
      "0.897106973057\n",
      "0.931300200178\n",
      "0.910139266853\n",
      "0.930083451422\n",
      "epoch3\n",
      "0.949284607961\n",
      "0.939612577807\n",
      "0.943529427105\n",
      "0.923610171522\n",
      "0.903751724741\n",
      "0.9420156665\n",
      "0.920809419733\n",
      "0.930369870277\n",
      "epoch4\n",
      "0.952350252754\n",
      "0.943694712443\n",
      "0.944592762039\n",
      "0.928342039318\n",
      "0.911426687614\n",
      "0.943477383045\n",
      "0.921747729323\n",
      "0.940144298911\n",
      "complete prediction\n",
      "complete computing norm\n",
      "#############2\n",
      "epoch0\n",
      "0.799711852891\n",
      "0.790056775055\n",
      "0.797533252116\n",
      "0.770540294655\n",
      "0.778202125643\n",
      "0.782020214368\n",
      "0.78976485801\n",
      "0.825890569994\n",
      "epoch1\n",
      "0.882896288906\n",
      "0.837644742897\n",
      "0.870271044464\n",
      "0.851622671655\n",
      "0.834099552073\n",
      "0.840702304982\n",
      "0.855592008651\n",
      "0.866385285865\n",
      "epoch2\n",
      "0.940099619682\n",
      "0.90047594502\n",
      "0.911812402413\n",
      "0.896672368439\n",
      "0.86606781818\n",
      "0.890372003013\n",
      "0.866931237164\n",
      "0.902727812128\n",
      "epoch3\n",
      "0.938015047608\n",
      "0.90624398623\n",
      "0.912271095722\n",
      "0.883448171579\n",
      "0.863491771673\n",
      "0.893359605132\n",
      "0.891354225809\n",
      "0.89206966282\n",
      "epoch4\n",
      "0.941746475039\n",
      "0.905155091528\n",
      "0.913729042725\n",
      "0.897466427395\n",
      "0.872213669563\n",
      "0.898548459233\n",
      "0.884586093677\n",
      "0.89333449476\n",
      "complete prediction\n",
      "complete computing norm\n",
      "#############3\n",
      "epoch0\n",
      "0.817388195532\n",
      "0.79296818898\n",
      "0.803581694203\n",
      "0.798267322864\n",
      "0.806627143016\n",
      "0.806968282224\n",
      "0.78118243114\n",
      "0.834924318719\n",
      "epoch1\n",
      "0.934010295501\n",
      "0.864558424422\n",
      "0.919607681774\n",
      "0.884644273218\n",
      "0.880256338246\n",
      "0.91493388868\n",
      "0.86478789655\n",
      "0.909158428643\n",
      "epoch2\n",
      "0.944383745778\n",
      "0.927825344114\n",
      "0.927789793541\n",
      "0.914818639716\n",
      "0.885664687215\n",
      "0.93309575757\n",
      "0.901576649674\n",
      "0.913625428675\n",
      "epoch3\n",
      "0.950257230867\n",
      "0.931894926363\n",
      "0.939535608312\n",
      "0.910265606744\n",
      "0.879679547407\n",
      "0.922546104154\n",
      "0.903727609587\n",
      "0.931890658463\n",
      "epoch4\n",
      "0.950131347102\n",
      "0.936516224081\n",
      "0.943493836185\n",
      "0.893236043098\n",
      "0.870940570165\n",
      "0.928430577347\n",
      "0.90318304302\n",
      "0.930629747511\n",
      "complete prediction\n",
      "complete computing norm\n",
      "#############4\n",
      "epoch0\n",
      "0.819530131755\n",
      "0.833106430622\n",
      "0.863395388682\n",
      "0.818613477656\n",
      "0.836515785401\n",
      "0.835786502699\n",
      "0.832481632992\n",
      "0.779520540435\n",
      "epoch1\n",
      "0.932979490328\n",
      "0.926497180428\n",
      "0.934502437562\n",
      "0.880131917852\n",
      "0.885749597377\n",
      "0.902120341814\n",
      "0.889208116541\n",
      "0.889957575824\n",
      "epoch2\n",
      "0.953524433725\n",
      "0.930465691105\n",
      "0.923134715816\n",
      "0.889514219943\n",
      "0.895903302791\n",
      "0.923578071081\n",
      "0.891881692671\n",
      "0.913383392183\n",
      "epoch3\n",
      "0.956828343622\n",
      "0.925713726613\n",
      "0.930402708319\n",
      "0.900370500535\n",
      "0.902612689254\n",
      "0.917836889607\n",
      "0.902013230555\n",
      "0.920449130837\n",
      "epoch4\n",
      "0.956018116389\n",
      "0.931564465194\n",
      "0.920201690154\n",
      "0.882353425883\n",
      "0.897407355841\n",
      "0.912957642412\n",
      "0.898230554749\n",
      "0.924998147173\n",
      "complete prediction\n",
      "complete computing norm\n",
      "#############5\n",
      "epoch0\n",
      "0.853840572292\n",
      "0.795969238205\n",
      "0.853000775596\n",
      "0.804315743528\n",
      "0.851226064283\n",
      "0.827074694339\n",
      "0.848430572067\n",
      "0.853278087932\n",
      "epoch1\n",
      "0.934063140815\n",
      "0.910487367001\n",
      "0.925790536487\n",
      "0.90311466789\n",
      "0.873278406591\n",
      "0.918690228786\n",
      "0.906471040675\n",
      "0.899656261629\n",
      "epoch2\n",
      "0.956487005114\n",
      "0.927299983031\n",
      "0.930193254932\n",
      "0.910872920003\n",
      "0.87566591758\n",
      "0.915273485707\n",
      "0.907940876586\n",
      "0.933484529037\n",
      "epoch3\n",
      "0.957602069827\n",
      "0.938583826311\n",
      "0.939524912845\n",
      "0.911005588536\n",
      "0.897607347367\n",
      "0.936928665819\n",
      "0.924095085295\n",
      "0.932786011209\n",
      "epoch4\n",
      "0.958476940131\n",
      "0.930858423486\n",
      "0.938833129433\n",
      "0.900429510105\n",
      "0.886490637896\n",
      "0.922320234655\n",
      "0.905756253815\n",
      "0.924152315222\n",
      "complete prediction\n",
      "complete computing norm\n",
      "#############6\n",
      "epoch0\n",
      "0.864924810566\n",
      "0.833395262516\n",
      "0.846937862207\n",
      "0.883290947259\n",
      "0.784646992475\n",
      "0.873670133642\n",
      "0.819606060382\n",
      "0.87209583948\n",
      "epoch1\n",
      "0.955784449427\n",
      "0.927317676684\n",
      "0.926519136861\n",
      "0.912921723109\n",
      "0.888600838642\n",
      "0.928262118012\n",
      "0.905701395055\n",
      "0.919702248806\n",
      "epoch2\n",
      "0.960216768874\n",
      "0.937475017565\n",
      "0.933185413042\n",
      "0.915026700176\n",
      "0.8940481169\n",
      "0.934334925179\n",
      "0.91537547704\n",
      "0.931521631695\n",
      "epoch3\n",
      "0.960872246961\n",
      "0.931508751727\n",
      "0.936906012002\n",
      "0.917789850279\n",
      "0.895202397044\n",
      "0.923968929459\n",
      "0.904867815263\n",
      "0.933666210762\n",
      "epoch4\n",
      "0.960635544531\n",
      "0.940054075419\n",
      "0.943431280753\n",
      "0.905095359502\n",
      "0.889469388483\n",
      "0.93224307906\n",
      "0.901483862238\n",
      "0.935218642351\n",
      "complete prediction\n",
      "complete computing norm\n",
      "#############7\n",
      "epoch0\n",
      "0.922850220929\n",
      "0.912534371639\n",
      "0.898680556625\n",
      "0.823820802139\n",
      "0.843955055485\n",
      "0.898087952872\n",
      "0.822264711137\n",
      "0.898764066224\n",
      "epoch1\n",
      "0.95342528908\n",
      "0.939953756186\n",
      "0.933653521113\n",
      "0.903655876356\n",
      "0.895549113721\n",
      "0.934633928479\n",
      "0.910403698348\n",
      "0.935331163365\n",
      "epoch2\n",
      "0.958610841151\n",
      "0.939756815357\n",
      "0.936204340815\n",
      "0.917461298157\n",
      "0.904299881984\n",
      "0.937558716264\n",
      "0.91630147726\n",
      "0.929228121877\n",
      "epoch3\n",
      "0.960530749667\n",
      "0.947719043358\n",
      "0.943919626585\n",
      "0.915595833021\n",
      "0.90521909948\n",
      "0.946384115262\n",
      "0.913948577679\n",
      "0.93537810886\n",
      "epoch4\n",
      "0.961133161963\n",
      "0.943789153236\n",
      "0.937562834196\n",
      "0.915127591515\n",
      "0.898355224432\n",
      "0.942646911645\n",
      "0.907617855845\n",
      "0.935118318537\n",
      "complete prediction\n",
      "complete computing norm\n",
      "#############8\n",
      "epoch0\n",
      "0.866452963965\n",
      "0.920195890967\n",
      "0.916280618067\n",
      "0.846450191967\n",
      "0.846883338157\n",
      "0.901778834429\n",
      "0.895006730066\n",
      "0.909654897588\n",
      "epoch1\n",
      "0.956418330222\n",
      "0.937680609272\n",
      "0.935437041227\n",
      "0.916840630265\n",
      "0.890133546474\n",
      "0.937106980226\n",
      "0.923091371116\n",
      "0.935074682641\n",
      "epoch2\n",
      "0.960837369936\n",
      "0.947111188953\n",
      "0.940342937587\n",
      "0.919670413593\n",
      "0.904232537862\n",
      "0.948423019327\n",
      "0.914584789467\n",
      "0.927629814651\n",
      "epoch3\n",
      "0.961516165213\n",
      "0.944785429866\n",
      "0.937264028264\n",
      "0.919312840034\n",
      "0.905989482104\n",
      "0.944169127783\n",
      "0.921379579182\n",
      "0.938166111071\n",
      "epoch4\n",
      "0.959021865791\n",
      "0.947942124475\n",
      "0.940577243711\n",
      "0.919570913287\n",
      "0.890402856795\n",
      "0.934910316917\n",
      "0.888529512815\n",
      "0.926280159495\n",
      "complete prediction\n",
      "complete computing norm\n",
      "#############9\n",
      "epoch0\n",
      "0.912869810527\n",
      "0.921456988939\n",
      "0.926339469832\n",
      "0.902381041763\n",
      "0.877052659692\n",
      "0.913692969141\n",
      "0.871704759622\n",
      "0.921648288551\n",
      "epoch1\n",
      "0.953168382695\n",
      "0.939554095375\n",
      "0.938780380149\n",
      "0.913442812616\n",
      "0.891834353413\n",
      "0.923287047444\n",
      "0.905061963936\n",
      "0.930372680824\n",
      "epoch2\n",
      "0.962738406673\n",
      "0.946572214891\n",
      "0.944052091438\n",
      "0.906654217154\n",
      "0.90496492032\n",
      "0.938933335225\n",
      "0.915127873397\n",
      "0.944984521172\n",
      "epoch3\n",
      "0.963394160155\n",
      "0.949277093611\n",
      "0.947246027552\n",
      "0.930640687735\n",
      "0.908040716025\n",
      "0.942490026558\n",
      "0.922099572764\n",
      "0.943006358376\n",
      "epoch4\n",
      "0.964132084247\n",
      "0.948107161255\n",
      "0.933902654467\n",
      "0.926242085609\n",
      "0.870996675565\n",
      "0.926248355161\n",
      "0.906655914321\n",
      "0.936535895658\n",
      "complete prediction\n",
      "complete computing norm\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dropout\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['5'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['5'][-num_validation_samples:]\n",
    "\n",
    "\n",
    "yt = np.array(labels[indices][:-num_validation_samples], dtype = float)\n",
    "yv = np.array(labels[indices][-num_validation_samples:], dtype = float)\n",
    "\n",
    "\n",
    "final_result = []\n",
    "\n",
    "labeled_idx = np.array(range(0,1000))\n",
    "unlabeled_idx = np.array(range(1000,x_train.shape[0]))\n",
    "\n",
    "for j in range(10):\n",
    "    print '#############'+str(j)\n",
    "    \n",
    "    ################model 1##################\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=False)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    #x = Dropout(0.2)(embedded_sequences)\n",
    "    x = Conv1D(128, 3, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    #x = Conv1D(128, 3, activation='relu')(x)\n",
    "    #x = MaxPooling1D(3)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv1D(128, 3, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    preds1 = Dense(6, activation='sigmoid')(x)\n",
    "    \n",
    "    model1 = Model(sequence_input, preds1)\n",
    "    model1.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "    \n",
    "    ################model 2##################\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=False)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    #x = Dropout(0.2)(embedded_sequences)\n",
    "    x = Conv1D(128, 4, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    #x = Conv1D(128, 4, activation='relu')(x)\n",
    "    #x = MaxPooling1D(4)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv1D(128, 4, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    preds2 = Dense(6, activation='sigmoid')(x)\n",
    "    \n",
    "    model2 = Model(sequence_input, preds2)\n",
    "    model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "    \n",
    "    ################model 3##################\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=False)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    #x = Dropout(0.2)(embedded_sequences)\n",
    "    x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    #x = Conv1D(128, 5, activation='relu')(x)\n",
    "    #x = MaxPooling1D(5)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv1D(128, 5, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    preds3 = Dense(6, activation='sigmoid')(x)\n",
    "    \n",
    "    model3 = Model(sequence_input, preds3)\n",
    "    model3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "    \n",
    "    ################model 4##################\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=False)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    #x = Dropout(0.2)(embedded_sequences)\n",
    "    x = Conv1D(128, 6, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(6)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    #x = Conv1D(128, 6, activation='relu')(x)\n",
    "    #x = MaxPooling1D(6)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv1D(128, 6, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    preds4 = Dense(6, activation='sigmoid')(x)\n",
    "    \n",
    "    model4 = Model(sequence_input, preds4)\n",
    "    model4.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "    \n",
    "    ################model 5##################\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=False)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    #x = Dropout(0.2)(embedded_sequences)\n",
    "    x = Conv1D(128, 7, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(7)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    #x = Conv1D(128, 7, activation='relu')(x)\n",
    "    #x = MaxPooling1D(7)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv1D(128, 7, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    preds5 = Dense(6, activation='sigmoid')(x)\n",
    "    \n",
    "    model5 = Model(sequence_input, preds5)\n",
    "    model5.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "    \n",
    "    ################model 6##################\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=False)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    #x = Dropout(0.2)(embedded_sequences)\n",
    "    x = Conv1D(128, 8, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(8)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    #x = Conv1D(128, 8, activation='relu')(x)\n",
    "    #x = MaxPooling1D(8)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv1D(128, 8, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    preds6 = Dense(6, activation='sigmoid')(x)\n",
    "    \n",
    "    model6 = Model(sequence_input, preds6)\n",
    "    model6.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "    \n",
    "    ################model 7##################\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=False)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    #x = Dropout(0.2)(embedded_sequences)\n",
    "    x = Conv1D(128, 9, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(9)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    #x = Conv1D(128, 9, activation='relu')(x)\n",
    "    #x = MaxPooling1D(9)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv1D(128, 9, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    preds7 = Dense(6, activation='sigmoid')(x)\n",
    "    \n",
    "    model7 = Model(sequence_input, preds7)\n",
    "    model7.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "    \n",
    "    ################model 8##################\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=False)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    #x = Dropout(0.2)(embedded_sequences)\n",
    "    x = Conv1D(128, 10, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(10)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    #x = Conv1D(128, 10, activation='relu')(x)\n",
    "    #x = MaxPooling1D(10)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv1D(128, 10, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    preds8 = Dense(6, activation='sigmoid')(x)\n",
    "    \n",
    "    model8 = Model(sequence_input, preds8)\n",
    "    model8.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "    ############################################\n",
    "    \n",
    "    result_list = []\n",
    "    for i in range(5):\n",
    "        result = []\n",
    "        print 'epoch'+str(i)\n",
    "        model1.fit(x_train[labeled_idx], yt[labeled_idx],\n",
    "                  batch_size=128,\n",
    "                  verbose = 0,\n",
    "                  validation_data=(x_val, yv))\n",
    "        model2.fit(x_train[labeled_idx], yt[labeled_idx],\n",
    "                  batch_size=128,\n",
    "                  verbose = 0,\n",
    "                  validation_data=(x_val, yv))\n",
    "        model3.fit(x_train[labeled_idx], yt[labeled_idx],\n",
    "                  batch_size=128,\n",
    "                  verbose = 0,\n",
    "                  validation_data=(x_val, yv))\n",
    "        model4.fit(x_train[labeled_idx], yt[labeled_idx],\n",
    "                  batch_size=128,\n",
    "                  verbose = 0,\n",
    "                  validation_data=(x_val, yv))\n",
    "        model5.fit(x_train[labeled_idx], yt[labeled_idx],\n",
    "                  batch_size=128,\n",
    "                  verbose = 0,\n",
    "                  validation_data=(x_val, yv))\n",
    "        model6.fit(x_train[labeled_idx], yt[labeled_idx],\n",
    "                  batch_size=128,\n",
    "                  verbose = 0,\n",
    "                  validation_data=(x_val, yv))\n",
    "        model7.fit(x_train[labeled_idx], yt[labeled_idx],\n",
    "                  batch_size=128,\n",
    "                  verbose = 0,\n",
    "                  validation_data=(x_val, yv))\n",
    "        model8.fit(x_train[labeled_idx], yt[labeled_idx],\n",
    "                  batch_size=128,\n",
    "                  verbose = 0,\n",
    "                  validation_data=(x_val, yv))\n",
    "        \n",
    "        y_pred = model1.predict(x_val, verbose=0)\n",
    "        validation_score = roc_auc_score(yv, y_pred)\n",
    "        print validation_score\n",
    "        result.append(validation_score)\n",
    "        \n",
    "        y_pred = model2.predict(x_val, verbose=0)\n",
    "        validation_score = roc_auc_score(yv, y_pred)\n",
    "        print validation_score\n",
    "        result.append(validation_score)\n",
    "        \n",
    "        y_pred = model3.predict(x_val, verbose=0)\n",
    "        validation_score = roc_auc_score(yv, y_pred)\n",
    "        print validation_score\n",
    "        result.append(validation_score)\n",
    "        \n",
    "        y_pred = model4.predict(x_val, verbose=0)\n",
    "        validation_score = roc_auc_score(yv, y_pred)\n",
    "        print validation_score\n",
    "        result.append(validation_score)\n",
    "        \n",
    "        y_pred = model5.predict(x_val, verbose=0)\n",
    "        validation_score = roc_auc_score(yv, y_pred)\n",
    "        print validation_score\n",
    "        result.append(validation_score)\n",
    "        \n",
    "        y_pred = model6.predict(x_val, verbose=0)\n",
    "        validation_score = roc_auc_score(yv, y_pred)\n",
    "        print validation_score\n",
    "        result.append(validation_score)\n",
    "        \n",
    "        y_pred = model7.predict(x_val, verbose=0)\n",
    "        validation_score = roc_auc_score(yv, y_pred)\n",
    "        print validation_score\n",
    "        result.append(validation_score)\n",
    "        \n",
    "        y_pred = model8.predict(x_val, verbose=0)\n",
    "        validation_score = roc_auc_score(yv, y_pred)\n",
    "        print validation_score\n",
    "        result.append(validation_score)\n",
    "        \n",
    "        result_list.append(result)\n",
    "    \n",
    "    pred1 = model1.predict(x_train[unlabeled_idx])\n",
    "    pred2 = model2.predict(x_train[unlabeled_idx])\n",
    "    pred3 = model3.predict(x_train[unlabeled_idx])\n",
    "    pred4 = model4.predict(x_train[unlabeled_idx])\n",
    "    pred5 = model5.predict(x_train[unlabeled_idx])\n",
    "    pred6 = model6.predict(x_train[unlabeled_idx])\n",
    "    pred7 = model7.predict(x_train[unlabeled_idx])\n",
    "    pred8 = model8.predict(x_train[unlabeled_idx])\n",
    "    print 'complete prediction'\n",
    "\n",
    "    conf1 = np.linalg.norm(pred1 - yt[unlabeled_idx], axis = 1)\n",
    "    conf2 = np.linalg.norm(pred2 - yt[unlabeled_idx], axis = 1)\n",
    "    conf3 = np.linalg.norm(pred3 - yt[unlabeled_idx], axis = 1)\n",
    "    conf4 = np.linalg.norm(pred4 - yt[unlabeled_idx], axis = 1)\n",
    "    conf5 = np.linalg.norm(pred5 - yt[unlabeled_idx], axis = 1)\n",
    "    conf6 = np.linalg.norm(pred6 - yt[unlabeled_idx], axis = 1)\n",
    "    conf7 = np.linalg.norm(pred7 - yt[unlabeled_idx], axis = 1)\n",
    "    conf8 = np.linalg.norm(pred8 - yt[unlabeled_idx], axis = 1)\n",
    "    print 'complete computing norm'\n",
    "\n",
    "    confidence = conf1 + conf2 + conf3 + conf4 + conf5 + conf6 + conf7 + conf8\n",
    "    max_idx = np.argpartition(confidence, -1000)[-1000:]\n",
    "    labeled_idx = np.append(labeled_idx, unlabeled_idx[max_idx])\n",
    "    unlabeled_idx = np.delete(unlabeled_idx, max_idx)\n",
    "    \n",
    "    final_result.append(result_list)\n",
    "    del model1, model2, model3, model4, model5, model6, model7, model8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qbc_result = np.mean(np.array(final_result),axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_result = np.load('data_without_modelpool.npy')\n",
    "cnn_result = cnn_result[:,:5,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparison of CNN and QBC-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxwAAAGcCAYAAABTKKb5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa7bc1f9090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,6), dpi=80)\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Normal Convolution Neural Network')\n",
    "plt.plot(range(1,10), cnn_result[:,0], color=\"blue\", linewidth=1.0, linestyle=\"-\", label=\"epoch1\")\n",
    "plt.plot(range(1,10), cnn_result[:,1], color=\"green\", linewidth=1.0, linestyle=\"-\", label=\"epoch2\")\n",
    "plt.plot(range(1,10), cnn_result[:,2], color=\"red\", linewidth=1.0, linestyle=\"-\", label=\"epoch3\")\n",
    "plt.plot(range(1,10), cnn_result[:,3], color=\"black\", linewidth=1.0, linestyle=\"-\", label=\"epoch4\")\n",
    "plt.plot(range(1,10), cnn_result[:,4], color=\"yellow\", linewidth=1.0, linestyle=\"-\", label=\"epoch5\")\n",
    "plt.ylim((0.6,1))\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Semi-supervised CNN by QBC')\n",
    "plt.plot(range(1,10), qbc_result[:9,0], color=\"blue\", linewidth=1.0, linestyle=\"-\", label=\"epoch1\")\n",
    "plt.plot(range(1,10), qbc_result[:9,1], color=\"green\", linewidth=1.0, linestyle=\"-\", label=\"epoch2\")\n",
    "plt.plot(range(1,10), qbc_result[:9,2], color=\"red\", linewidth=1.0, linestyle=\"-\", label=\"epoch3\")\n",
    "plt.plot(range(1,10), qbc_result[:9,3], color=\"black\", linewidth=1.0, linestyle=\"-\", label=\"epoch4\")\n",
    "plt.plot(range(1,10), qbc_result[:9,4], color=\"yellow\", linewidth=1.0, linestyle=\"-\", label=\"epoch5\")\n",
    "plt.ylim((0.6,1))\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/5\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9699\n",
      " ROC-AUC - epoch: 1 - score: 0.968838\n",
      "127657/127657 [==============================] - 386s - loss: 0.1016 - acc: 0.9699 - val_loss: 0.0541 - val_acc: 0.9808\n",
      "Epoch 2/5\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9817\n",
      " ROC-AUC - epoch: 2 - score: 0.971560\n",
      "127657/127657 [==============================] - 384s - loss: 0.0516 - acc: 0.9817 - val_loss: 0.0514 - val_acc: 0.9816\n",
      "Epoch 3/5\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9829\n",
      " ROC-AUC - epoch: 3 - score: 0.972797\n",
      "127657/127657 [==============================] - 394s - loss: 0.0471 - acc: 0.9829 - val_loss: 0.0502 - val_acc: 0.9817\n",
      "Epoch 4/5\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9839\n",
      " ROC-AUC - epoch: 4 - score: 0.973148\n",
      "127657/127657 [==============================] - 383s - loss: 0.0435 - acc: 0.9839 - val_loss: 0.0509 - val_acc: 0.9815\n",
      "Epoch 5/5\n",
      "127616/127657 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9848\n",
      " ROC-AUC - epoch: 5 - score: 0.972091\n",
      "127657/127657 [==============================] - 386s - loss: 0.0402 - acc: 0.9848 - val_loss: 0.0520 - val_acc: 0.9816\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcba46a3810>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GlobalMaxPool1D\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dropout\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
    "\n",
    "\n",
    "inp = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "x = Embedding(num_words, EMBEDDING_DIM)(inp)\n",
    "x = LSTM(60, return_sequences=True,name='lstm_layer')(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label['5'][:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label['5'][-num_validation_samples:]\n",
    "\n",
    "\n",
    "yt = labels[indices][:-num_validation_samples]\n",
    "yv = np.array(labels[indices][-num_validation_samples:], dtype = float)\n",
    "\n",
    "ra = RocAucEvaluation(validation_data=(x_val, yv), interval = 1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=1, verbose=1)\n",
    "\n",
    "model.fit(x_train, yt,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks = [ra, early_stopping],\n",
    "          validation_data=(x_val, yv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model_alllabel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think the possibility of this sentence to be \n",
      "toxic is 0.503438830376, \n",
      "severe_toxic 0.00307771121152,         \n",
      "obscene 0.0739611461759, \n",
      "threat 0.0122219342738, \n",
      "insult 0.156958609819, \n",
      "identity_hate 0.0310209169984\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAGzCAYAAAAmH71NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAByLoAMAAByLoAMAABzr/wFlgw0luTOTxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3d09cbe890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test1 = tokenizer.texts_to_sequences([\"552 is a bad course\"])\n",
    "test2 = pad_sequences(test1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "pred = model.predict(test2)[0]\n",
    "\n",
    "print 'I think the possibility of this sentence to be \\ntoxic is {}, \\nsevere_toxic {}, \\\n",
    "        \\nobscene {}, \\nthreat {}, \\ninsult {}, \\nidentity_hate {}'.format(pred[0], pred[1],\\\n",
    "                                                                  pred[2], pred[3], pred[4], pred[5])\n",
    " \n",
    "objects = ('toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = pred\n",
    " \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel('Possibility')\n",
    "plt.title('Prediction Result')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
