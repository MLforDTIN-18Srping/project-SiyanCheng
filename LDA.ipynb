{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FP = 'train.csv'\n",
    "TEST_FP = 'test.csv'\n",
    "MAX_NUM_WORDS = 1500\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import re\n",
    "\n",
    "train_data, test_data = pd.read_csv(TRAIN_FP), pd.read_csv(TEST_FP)\n",
    "'''\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "train_data['comment_text'] = train_data['comment_text'].map(lambda com : clean_text(com))\n",
    "'''\n",
    "texts = train_data.values[:,1]\n",
    "labels = np.array(train_data.values[:,2:], dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 58.797s.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from time import time\n",
    "\n",
    "num_samples = len(texts)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=20000, lowercase=True, analyzer='word',\n",
    "                        stop_words= 'english',ngram_range=(1,3),dtype=np.float32)\n",
    "t0 = time()\n",
    "train_tfidf_data = tfidf_vectorizer.fit_transform(texts[0:int(num_samples*0.7)])\n",
    "test_tfidf_data = tfidf_vectorizer.transform(texts[int(num_samples*0.7):])\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 62.019s.\n"
     ]
    }
   ],
   "source": [
    "tf_vectorizer = CountVectorizer(max_features=20000, lowercase=True, analyzer='word',\n",
    "                        stop_words= 'english',ngram_range=(1,3),dtype=np.float32)\n",
    "t0 = time()\n",
    "train_tf_data = tf_vectorizer.fit_transform(texts[0:int(num_samples*0.7)])\n",
    "test_tf_data = tf_vectorizer.transform(texts[int(num_samples*0.7):])\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy for label0is: 0.937061330214\n",
      "accuracy for label1is: 0.979612299465\n",
      "accuracy for label2is: 0.97347092246\n",
      "accuracy for label3is: 0.995947526738\n",
      "accuracy for label4is: 0.961564171123\n",
      "accuracy for label5is: 0.980656751337\n",
      "accuracy: 0.878425802139\n",
      "overall Roc score is : 0.962313205572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_label = labels[0:int(num_samples*0.7)]\n",
    "test_label = labels[int(num_samples*0.7):]\n",
    "\n",
    "roc_pred = np.zeros((test_tfidf_data.shape[0],6))\n",
    "y_pred = np.zeros((test_tfidf_data.shape[0],6))\n",
    "parameters = {'C':[.01, .1, 1, 10, 100, 1000]}\n",
    "\n",
    "for i in range(6):\n",
    "    lr = LogisticRegression(class_weight = 'balanced')\n",
    "    clf = GridSearchCV(lr, parameters)\n",
    "    clf.fit(train_tfidf_data, train_label[:,i])\n",
    "    # compute the training accuracy\n",
    "    lr = LogisticRegression(C = clf.best_params_['C'],class_weight = 'balanced')\n",
    "    lr.fit(train_tfidf_data, train_label[:,i])\n",
    "    y_pred[:,i] = lr.predict(test_tfidf_data)\n",
    "    print 'accuracy for label'+str(i)+'is:', accuracy_score(test_label[:,i], y_pred[:,i])\n",
    "    roc_pred[:,i] = lr.predict_proba(test_tfidf_data)[:,1]\n",
    "\n",
    "def compute_acc(y_pred, y_val):\n",
    "    result = 0.0\n",
    "    num_sample = y_pred.shape[0]\n",
    "    for i in range(num_sample):\n",
    "        if np.array_equal(y_pred[i], y_val[i]):\n",
    "            result = result + 1\n",
    "    return result/num_sample\n",
    "        \n",
    "    \n",
    "\n",
    "print 'accuracy:',compute_acc(y_pred, test_label)\n",
    "print 'overall Roc score is :', roc_auc_score(test_label, roc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for label0is: 0.952811664439\n",
      "accuracy for label1is: 0.989847927807\n",
      "accuracy for label2is: 0.980092747326\n",
      "accuracy for label3is: 0.997284425134\n",
      "accuracy for label4is: 0.969355782086\n",
      "accuracy for label5is: 0.991477272727\n",
      "accuracy: 0.914835394385\n",
      "overall Roc score is : 0.934777300828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "roc_pred = np.zeros((test_tfidf_data.shape[0],6))\n",
    "y_pred = np.zeros((test_tfidf_data.shape[0],6))\n",
    "parameters = {'C':[.01, .1, 1, 10, 100, 1000]}\n",
    "train_label = labels[0:int(num_samples*0.7)]\n",
    "test_label = labels[int(num_samples*0.7):]\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "            max_depth=100, max_features=1000,\n",
    "            min_samples_leaf=3, min_samples_split=10,\n",
    "            n_estimators=10)\n",
    "    \n",
    "    clf.fit(train_tfidf_data, train_label[:,i])\n",
    "    # compute the training accuracy\n",
    "    #svc = SVC(C = clf.best_params_['C'], class_weight = 'balanced')\n",
    "    #svc.fit(train_tfidf_data, train_label[:,i])\n",
    "    y_pred[:,i] = clf.predict(test_tfidf_data)\n",
    "    print 'accuracy for label'+str(i)+'is:', accuracy_score(test_label[:,i], y_pred[:,i])\n",
    "    roc_pred[:,i] = clf.predict_proba(test_tfidf_data)[:,1]\n",
    "\n",
    "print 'accuracy:',compute_acc(y_pred, test_label)\n",
    "print 'overall Roc score is :', roc_auc_score(test_label, roc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _**Using Term-Frequency Feature**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.862\n",
      "done in 19.169s.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_topics=2, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "texts = train_data.values[:,1]\n",
    "labels = np.asarray(train_data.values[:,2],dtype='int')\n",
    "train_label = labels[0:int(num_samples*0.7)]\n",
    "test_label = labels[int(num_samples*0.7):]\n",
    "\n",
    "t0 = time()\n",
    "i = 0\n",
    "while True:\n",
    "    if i*2000+2000 > (num_samples*0.7):\n",
    "        lda.partial_fit(train_tf_data[i*2000:])\n",
    "        result = lda.transform(test_tf_data[0:1000])\n",
    "        print accuracy_score(test_label[0:1000], np.asarray(result[:,0]<result[:,1],dtype = 'int'))\n",
    "        break\n",
    "    lda.partial_fit(train_tf_data[i*2000:i*2000+2000])\n",
    "    result = lda.transform(test_tf_data[0:1000])\n",
    "    #print accuracy_score(test_label[0:1000], np.asarray(result[:,0]<result[:,1],dtype = 'int'))\n",
    "    i = i + 1\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.860544786096\n"
     ]
    }
   ],
   "source": [
    "result = lda.transform(test_tf_data)\n",
    "print accuracy_score(test_label, np.asarray(result[:,0]<result[:,1],dtype = 'int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _**Using Term-Frequency-IDF Feature**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.573\n",
      "done in 17.600s.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_topics=2, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "texts = train_data.values[:,1]\n",
    "labels = np.asarray(train_data.values[:,2],dtype='int')\n",
    "train_label = labels[0:int(num_samples*0.7)]\n",
    "test_label = labels[int(num_samples*0.7):]\n",
    "\n",
    "t0 = time()\n",
    "i = 0\n",
    "while True:\n",
    "    if i*2000+2000 > (num_samples*0.7):\n",
    "        lda.partial_fit(train_tfidf_data[i*2000:])\n",
    "        result = lda.transform(test_tfidf_data[0:1000])\n",
    "        print 1 - accuracy_score(test_label[0:1000], np.asarray(result[:,0]>result[:,1],dtype = 'int'))\n",
    "        break\n",
    "    lda.partial_fit(train_tfidf_data[i*2000:i*2000+2000])\n",
    "    result = 1 - lda.transform(test_tfidf_data[0:1000])\n",
    "    #print accuracy_score(test_label[0:1000], np.asarray(result[:,0]>result[:,1],dtype = 'int'))\n",
    "    i = i + 1\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.540232286096\n"
     ]
    }
   ],
   "source": [
    "result = lda.transform(test_tf_data)\n",
    "print accuracy_score(test_label, np.asarray(result[:,0]<result[:,1],dtype = 'int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.919222092246\n",
      "overall Roc score is : 0.966978861974\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "roc_pred = np.zeros((test_tfidf_data.shape[0],6))\n",
    "y_pred = np.zeros((test_tfidf_data.shape[0],6))\n",
    "parameters = {'C':[.01, .1, 1, 10, 100, 1000]}\n",
    "train_label = labels[0:int(num_samples*0.7)]\n",
    "test_label = labels[int(num_samples*0.7):]\n",
    "\n",
    "for i in range(6):\n",
    "    xgb_params = {'eta': 0.3, \n",
    "                  'max_depth': 5, \n",
    "                  'subsample': 0.8, \n",
    "                  'colsample_bytree': 0.8, \n",
    "                  'objective': 'binary:logistic', \n",
    "                  'eval_metric': 'auc', \n",
    "                  'seed': 23\n",
    "                 }\n",
    "\n",
    "    d_train = xgb.DMatrix(train_tfidf_data, train_label[:,i])\n",
    "    d_valid = xgb.DMatrix(test_tfidf_data, test_label[:,i])\n",
    "\n",
    "    watchlist = [(d_valid, 'valid')]\n",
    "    model = xgb.train(xgb_params, d_train, 200, watchlist, verbose_eval=False, early_stopping_rounds=30)\n",
    "    roc_pred[:,i] = model.predict(d_valid)\n",
    "\n",
    "print 'Overall accuracy:',compute_acc(roc_pred>0.5, test_label)\n",
    "print 'Overall Roc score is :', roc_auc_score(test_label, roc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
